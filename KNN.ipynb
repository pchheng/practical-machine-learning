{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours <img src=\"logo.png\",width=140,height=140, align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN is a simple classification algorithm. It classifies cases based on a similarity measure relying on the labels belonging to the K nearest points in the training set. In this notebook, we will show you how to do it with Scikit-Learn, and in the appendix we'll show you how to do it from scratch. Let's start with importing the required libraries for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import neighbors as neigh\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are already familiar with the dataset we use for this exercise, as we'll use the wine data again. This time, we have added the labels to the wines. The wines comes from the same region in Tuscany, Italy but are derived from three different cultivars. Did you discover 3 clusters in the last exercise? We're still working with the chemical features of the data, but we've added classes. \n",
    "\n",
    "The classes are given under the variables \"Class\" and \"Origin\" and are respectively:\n",
    "\n",
    "1. from Siena \n",
    "2. from Lucca\n",
    "3. from Pisa\n",
    "\n",
    "With our classficiaton algorithm we can predict where new, unseen wines are coming from. Let's  start by reading in the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/wine_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok great, so it looks like we've just added two columns to our dataset. Let's have a look at how our classes are divived. This is always important to do in classifications problems. We would ideally like each of our classes to be quite equal in size, otherwise we would have to address a problem of unbalanced classes. So let's create a bar chart of our classes, we'll take the variable 'Origin' but we could do the same with 'Class', as they're just the numeric and string representation of our classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wineorigin=pd.DataFrame(data['Origin'].value_counts())\n",
    "plt.figure()\n",
    "wineorigin.plot(kind='bar')\n",
    "plt.xlabel('Origin of wine')\n",
    "plt.ylabel('Number of instances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So...Do you think these classes are unbalanced?\n",
    "\n",
    "### Cross validation - splitting the data \n",
    "Now to test the algorithm, we first need to split the data into training and test set, and convert the parts to Numpy array. We'll use the train_test_split package in sklearn for that. We'll then have to split the classes out of the data to store it in a seperate \"Y\" variable. We can use \"Class\" for train_Y and the rest of the variables, without \"Origin\" for train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, train_size = 0.7)\n",
    "\n",
    "train_X = np.array(train)[:, 2:].astype(float)\n",
    "train_Y = np.array(train)[:,0].astype(float)\n",
    "\n",
    "test_X = np.array(test)[:, 2:].astype(float)\n",
    "test_Y = np.array(test)[:,0].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that our data is split into train and test data, let's run an 1 - NN algorithm on our data, using the sklearn library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K=1\n",
    "clf = neigh.KNeighborsClassifier(K)\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "predictions = clf.predict(test_X)\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(test_Y, predictions)*100\n",
    "print('Accuracy: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a look at the values in the data, we can see that they have different orders of magnitude for different features. Let's work our feature scaling magic and do a short exercise to scale our train_X set to make the different features better aligned.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** <br> Can you scale the train_X feature set and test_X set using the StandarScaler function, like we did before in the K-means exercise? Hint: if you get stuck, the answer is at the bottom of this notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler1  = # write here\n",
    "scaler2  = # write here\n",
    "\n",
    "train_Xscaled = # write here\n",
    "test_Xscaled= # write here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's put the scaled data into the K-NN algorithm and see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = 1\n",
    "clf = neigh.KNeighborsClassifier(K)\n",
    "clf.fit(train_Xscaled, train_Y)\n",
    "\n",
    "predictions = clf.predict(test_Xscaled)\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(test_Y, predictions)*100\n",
    "print('Accuracy: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "We can also investigate other metrics, such as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(test_Y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question:** Do you understand what these metrics mean? Is our model any good at predicting where wines come from? How is the fact that our dataset is relatively small weighing on these results? \n",
    "\n",
    "We can also try setting weights (i.e. using the distance of neighbours to weigh their relative importance), and see if our performance increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = 1\n",
    "clf = neigh.KNeighborsClassifier(K, weights='distance')\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "predictions = clf.predict(test_X)\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(test_Y, predictions)*100\n",
    "print('Accuracy: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we increase the  number of neighbours taken into account? We can plot the accuracy accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotvector(train_X, train_Y, test_X, test_Y, weights, upperLim = 100):\n",
    "    results = []\n",
    "    for k in range(1, upperLim, 4):\n",
    "        clf = neigh.KNeighborsClassifier(n_neighbors = k, weights = weights)\n",
    "        clf = clf.fit(train_X, train_Y)\n",
    "        preds = clf.predict(test_X)\n",
    "        accuracy = clf.score(test_X, test_Y)\n",
    "        results.append([k, accuracy*100])\n",
    " \n",
    "    results = np.array(results)\n",
    "    return(results)\n",
    "\n",
    "pltvector1 = plotvector(train_X, train_Y, test_X, test_Y, weights = \"uniform\")\n",
    "pltvector2 = plotvector(train_X, train_Y, test_X, test_Y,  weights = \"distance\")\n",
    "line1 = plt.plot(pltvector1[:,0], pltvector1[:,1], label = \"uniform\")\n",
    "line2 = plt.plot(pltvector2[:,0], pltvector2[:,1], label = \"distance\")\n",
    "plt.legend(loc=3)\n",
    "plt.ylim(60, 80)\n",
    "plt.title(\"Accuracy with Increasing K\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph looks quite funky, but that's again mostly because we have a very small dataset. Our results tend to jump around quite a bit because of it. Also, having a very high number of K on a very small dataset makes very little sense..\n",
    "\n",
    "We can also do a step of feature selection, in order to maintain only the most descriptive features. More specifically, the sklearn.feature_selection module can be used for feature selection/dimensionality reduction on sample sets, either to improve estimators’ accuracy scores or to boost their performance on very high-dimensional datasets. Univariate feature selection works by selecting the best features based on univariate statistical tests.\n",
    "\n",
    "First, we select the optimal number of features, through cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percentiles = range(1, 100, 5)\n",
    "results = []\n",
    "for i in range(1, 100, 5):\n",
    "    fs = feature_selection.SelectPercentile(sklearn.feature_selection.f_classif, percentile=i)\n",
    "    X_train_fs = fs.fit_transform(train_Xscaled, train_Y)\n",
    "    scores = cross_val_score(clf, X_train_fs, train_Y, cv=5)\n",
    "    results = np.append(results, scores.mean())\n",
    "\n",
    "optimal_percentil = np.where(results == results.max())[0]\n",
    "if len(optimal_percentil)>1:\n",
    "    optimal_percentil=optimal_percentil[0]\n",
    "\n",
    "print (\"Optimal percentil:\",optimal_percentil)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "import pylab as pl\n",
    "pl.figure()\n",
    "pl.xlabel(\"Number of features selected (%)\")\n",
    "pl.ylabel(\"Cross validation accuracy)\")\n",
    "pl.plot(percentiles,results)\n",
    "print (\"Mean scores:\",results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we select the relevant features and we repeat the KNN algorithm with the transformed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = sklearn.feature_selection.SelectPercentile(sklearn.feature_selection.f_classif, percentile=percentiles[optimal_percentil])\n",
    "X_train_fs = fs.fit_transform(train_Xscaled, train_Y)\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(5)\n",
    "\n",
    "clf.fit(X_train_fs, train_Y)\n",
    "X_test_fs = fs.transform(test_Xscaled)\n",
    "predictions = clf.predict(X_test_fs)\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(test_Y, predictions)*100\n",
    "print('Accuracy: ' + repr(accuracy) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens to accuracy if we change the ratio between training and test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Designing the K-NN algorithm yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the K-NN algorithm is very straightforward, you can easily set it up yourself. We would need to define all the functions we need to implement KNN classification algorithm. We'll do that below, to show you step by step how the KNN algorithm works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by calculating the distance between two data instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Euclidean Distance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def euclideanDistance(instance1, instance2):\n",
    "    length = len(instance1)\n",
    "    # you can also check if instance1 and instance2 have the same length\n",
    "    distance = 0\n",
    "    for l in range(length):\n",
    "        distance += (instance1[l] - instance2[l])**2\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1 = [0,1,2]\n",
    "data2 = [0,2,4]\n",
    "distance = euclideanDistance(data1, data2)\n",
    "print ('Distance: ', distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to get the K nearest neighbors of a point in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getNeighbors(data, labels, testInstance, K):\n",
    "    distances = []\n",
    "    neighbors = {}\n",
    "    #Finds the distances between all the points and creates a list of tuples.\n",
    "    for i in range(len(data)):\n",
    "        dist = euclideanDistance(testInstance, data[i, :])\n",
    "        distances.append([data[i,:], dist])\n",
    "\n",
    "    #Sorts the list of distances by using the second element of the tuple, i.e. the distance    \n",
    "\n",
    "    idx = np.argsort(np.array(distances)[:, 1])\n",
    "    neighbors_data = data[idx]\n",
    "    neighbors_label = labels[idx]\n",
    "    \n",
    "    neighbors =  {'data': neighbors_data[:K], 'labels': neighbors_label[:K]}\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define the training set: 2 points and 2 labels\n",
    "data = np.array([[2, 2, 2], [4, 4, 4]])\n",
    "labels = np.array([0, 1])\n",
    "\n",
    "# define the test instance\n",
    "testInstance = [5, 5, 5]\n",
    "\n",
    "# choose the number of neighbours\n",
    "K = 1\n",
    "\n",
    "# find & retrieve the K nearest points to the test instance, sorted by the distance\n",
    "neighbors = getNeighbors(data, labels, testInstance, K)\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a Response function: this counts the number of times a certain class appears in the set of neighbours that we've found with the previous function. The class with the highest frequency will be the label assigned to the test instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    #Assign the votes for every class\n",
    "    for i in range(len(neighbors)):\n",
    "        response = neighbors[i]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    \n",
    "    #Use the dictionary to short which class has the most votes\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #print sortedVotes\n",
    "    return sortedVotes[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# in this case we have two 1s and one 0: class 1 wins.\n",
    "neighbors['labels'] = np.array([1, 1, 0])\n",
    "response = getResponse(neighbors['labels'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the accuracy of our model: This should be a familiar concept by now, it is a way to test the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testSet)):\n",
    "        #If the label of the testSet and the prediction are the same add one.\n",
    "        if testSet[i] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (float(correct)/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# true labels\n",
    "testSet = np.array(['a','a','b'])\n",
    "\n",
    "# predicted labels\n",
    "predictions = ['a', 'a', 'a']\n",
    "\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** <br> Assign a label to the test instance, basing on the following training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = np.array([[1, 1, 1], [1, 3, 5], [7, 5, 4], [9, 5, 3]])\n",
    "training_labels = np.array([1, 2, 1, 2])\n",
    "test_instance = np.array([4, 4, 4])\n",
    "\n",
    "# get K neighbours\n",
    "K = #TYPEHERE\n",
    "neighbours = #TYPEHERE\n",
    "\n",
    "# get the label\n",
    "label = #TYPEHERE\n",
    "\n",
    "print label\n",
    "\n",
    "# what about the accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers to the Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** <br> Can you scale the train_X feature set and test_X set using the StandarScaler function, like we did before in the K-means exercise? Hint: if you get stuck, the answer is at the bottom of this notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler1  = preprocessing.StandardScaler().fit(train_X)\n",
    "scaler2  = preprocessing.StandardScaler().fit(test_X)\n",
    "\n",
    "train_Xscaled = scaler1.transform(train_X)\n",
    "test_Xscaled= scaler2.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** <br> Assign a label to the test instance, basing on the following training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get K neighbours\n",
    "K = 1\n",
    "neighbours = getNeighbors(training_set, training_labels, testInstance, K)\n",
    "\n",
    "# get the label\n",
    "label = getResponse(neighbours['labels'])\n",
    "\n",
    "print (label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Copyright © ASI 2017 All rights reserved"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
